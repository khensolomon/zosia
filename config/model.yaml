# config/model.yaml
# Defines the architecture of the Transformer model.
# These hyperparameters control the model's size, capacity, and complexity.

# Inherits base settings from default.yaml
defaults:
  - default

# --- Transformer Model Architecture ---
model:
  # The main dimensionality of the model for embeddings and transformer layers.
  # Must be divisible by num_heads.
  d_model: 512

  # The number of parallel attention heads in the multi-head attention mechanism.
  num_heads: 8

  # The number of encoder layers in the Transformer stack.
  num_encoder_layers: 6

  # The number of decoder layers in the Transformer stack.
  num_decoder_layers: 6

  # The dimensionality of the inner feed-forward network layer.
  # A common choice is 4 * d_model.
  d_ff: 2048

  # The dropout rate applied to various layers to prevent overfitting.
  dropout: 0.1

  # The maximum length of input/output sequences.
  # Sentences longer than this will be truncated.
  max_seq_len: 256
